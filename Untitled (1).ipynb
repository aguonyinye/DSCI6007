{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation by Collaborative Filtering using the Netflix Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Ratings\n",
    "\n",
    "One of the most common uses of big data is to predict what users want.Netflix to recommend movies that you might like.  This lab will demonstrate how we can use Apache Spark to recommend movies to a user.  We will start with some basic techniques, and then use the [sparkml] library's Alternating Least Squares method to make more sophisticated predictions.\n",
    "\n",
    "In this project, we will use MLlib to make personalized movie recommendations . We will work with 3.2 million ratings from 1821 movies and 28978 users , \n",
    "\n",
    "You will need to Spawn a Spark cluster and Jupyter Notebook server using the instructions provided in Sparkify 8, and upload a copy of this notebook to this Spark Notebook server. Also, you will have to upload the dataset (i.e., txt files) on S3.  The following cell defines the locations of the data files. You'll need to adjust the paths, below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change to the location of data files\n",
    "dbfs_dir = 's3://aguonyinyechidsci6007netflix/Netflix/Netflix/'\n",
    "movie_titles_filename = dbfs_dir + '/movie_titles.txt'\n",
    "TrainingRatings_filename = dbfs_dir + '/TrainingRatings.txt'\n",
    "TestingRatings_filename = dbfs_dir + '/TestingRatings.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to speed things up further by specifying the DataFrame schema explicitly. (When the Spark CSV adapter infers the schema from a txt file, it has to make an extra pass over the file. That'll slow things down here, and it isn't really necessary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "movie_titles_df_schema = StructType(\n",
    "  [StructField('ID', IntegerType()),\n",
    "   StructField('movie_year', IntegerType()),\n",
    "   StructField('movie_title', StringType())]\n",
    ")\n",
    "TrainingRatings_df_schema = StructType(\n",
    "  [StructField('movie_Id', IntegerType()),\n",
    "   StructField('user_Id', IntegerType()),\n",
    "   StructField('movie_ratings', FloatType())]\n",
    ")\n",
    "TestingRatings_df_schema = StructType(\n",
    "  [StructField('movie_Id', IntegerType()),\n",
    "   StructField('user_Id', IntegerType()),\n",
    "   StructField('movie_ratings', FloatType())]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Cache\n",
    "By now, your datasets should be hosted on S3. We're going to be accessing this data a lot. Rather than read it over and over again from S3, we'll cache both the movies DataFrame and the ratings DataFrame in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17770 movietitle, 3255352 trainingRatings and 100478 testingRatings in the datasets\n",
      "Movie_titles:\n",
      "+---+----------+--------------------+\n",
      "| ID|movie_year|         movie_title|\n",
      "+---+----------+--------------------+\n",
      "|  1|      2003|     Dinosaur Planet|\n",
      "|  2|      2004|Isle of Man TT 20...|\n",
      "|  3|      1997|           Character|\n",
      "+---+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "TrainingRatings:\n",
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|8       |1744889|1.0          |\n",
      "|8       |1395430|2.0          |\n",
      "|8       |1205593|4.0          |\n",
      "+--------+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "TestingRatings:\n",
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|8       |573364 |1.0          |\n",
      "|8       |2149668|3.0          |\n",
      "|8       |1089184|3.0          |\n",
      "+--------+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "raw_movie_titles_df = sqlContext.read.format('csv').options(inferSchema=False).schema(movie_titles_df_schema).load(movie_titles_filename)\n",
    "movie_titles_df= raw_movie_titles_df\n",
    "\n",
    "raw_TrainingRatings_df = sqlContext.read.format('csv').options(inferSchema=False).schema(TrainingRatings_df_schema).load(TrainingRatings_filename)\n",
    "TrainingRatings_df = raw_TrainingRatings_df\n",
    "\n",
    "raw_TestingRatings_df = sqlContext.read.format('csv').options(inferSchema=False).schema(TestingRatings_df_schema).load(TestingRatings_filename)\n",
    "TestingRatings_df = raw_TestingRatings_df\n",
    "\n",
    "movie_titles_df.cache()\n",
    "TrainingRatings_df.cache()\n",
    "TestingRatings_df.cache()\n",
    "\n",
    "assert movie_titles_df.is_cached\n",
    "assert TrainingRatings_df.is_cached\n",
    "assert TestingRatings_df.is_cached\n",
    "\n",
    "raw_movie_titles_count = raw_movie_titles_df.count()\n",
    "movie_titles_count = movie_titles_df.count()\n",
    "\n",
    "raw_TrainingRatings_count = raw_TrainingRatings_df.count()\n",
    "TrainingRatings_count = TrainingRatings_df.count()\n",
    "\n",
    "raw_TestingRatings_count = raw_TestingRatings_df.count()\n",
    "TestingRatings_count = TestingRatings_df.count()\n",
    "\n",
    "\n",
    "print('There are %s movietitle, %s trainingRatings and %s testingRatings in the datasets' % (movie_titles_count, TrainingRatings_count,TestingRatings_count))\n",
    "print('Movie_titles:')\n",
    "movie_titles_df.show(3)\n",
    "print ('TrainingRatings:')\n",
    "TrainingRatings_df.show(3, truncate=False)\n",
    "print ('TestingRatings:')\n",
    "TestingRatings_df.show(3, truncate=False)\n",
    "\n",
    "assert raw_movie_titles_count == movie_titles_count\n",
    "assert raw_TrainingRatings_count == TrainingRatings_count\n",
    "assert raw_TestingRatings_count == TestingRatings_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea on which similarity can be estimated more\n",
    "accurately, pick a user from the test set, extract the items this user has rated in the\n",
    "training set and compute how many other users in the training set have rated the\n",
    "same items. Let’s call this quantity overlap of an item for a given user. To get a\n",
    "comparison statistic you can average over all the items of that user and also\n",
    "perform this computation for multiple users from the test set to get an estimated\n",
    "average overlap of items forusers. Then do the same for items instead of users to get the\n",
    "estimated average overlap of users for items. Which number do you expect to be higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|     992|2149668|          3.0|\n",
      "|    1202|2149668|          3.0|\n",
      "|    1289|2149668|          1.0|\n",
      "|    1305|2149668|          3.0|\n",
      "|    2015|2149668|          5.0|\n",
      "|    2212|2149668|          3.0|\n",
      "|    2342|2149668|          4.0|\n",
      "|    2601|2149668|          3.0|\n",
      "|    2675|2149668|          3.0|\n",
      "|    2755|2149668|          3.0|\n",
      "|    2913|2149668|          5.0|\n",
      "|    2955|2149668|          5.0|\n",
      "|    3151|2149668|          4.0|\n",
      "|    3253|2149668|          4.0|\n",
      "|    3274|2149668|          2.0|\n",
      "|    3290|2149668|          5.0|\n",
      "|    3355|2149668|          5.0|\n",
      "|    3538|2149668|          4.0|\n",
      "|    4847|2149668|          3.0|\n",
      "|    4849|2149668|          3.0|\n",
      "+--------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|     992| 306466|          3.0|\n",
      "|     992| 765331|          4.0|\n",
      "|     992|  41412|          3.0|\n",
      "|     992|1331887|          3.0|\n",
      "|     992|1276913|          3.0|\n",
      "|     992| 887273|          4.0|\n",
      "|     992|1663216|          3.0|\n",
      "|     992|1778851|          5.0|\n",
      "|     992|2630287|          5.0|\n",
      "|     992| 530441|          5.0|\n",
      "+--------+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "movie_ids_with_avg_ratings_df:\n",
      "+-------+-----+------------------+\n",
      "|user_Id|count|average           |\n",
      "+-------+-----+------------------+\n",
      "|1896167|24   |3.375             |\n",
      "|128389 |42   |3.0238095238095237|\n",
      "|1552084|31   |3.7419354838709675|\n",
      "+-------+-----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AverageUser_df = TrainingRatings_df.filter(\"user_Id == 2149668\")\n",
    "AverageUser_df.show()\n",
    "\n",
    "\n",
    "list1 = AverageUser_df.select('movie_Id')\n",
    "array = [int(row.movie_Id) for row in list1.collect()]\n",
    "users = TrainingRatings_df[TrainingRatings_df['movie_Id'].isin(array)]\n",
    "users.show(10)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "itemsusers = users.groupBy('user_Id').agg(F.count(users.movie_ratings).alias(\"count\"),F.avg(users.movie_ratings).alias(\"average\"))\n",
    "print('movie_ids_with_avg_ratings_df:')\n",
    "itemsusers.show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|       8|1744889|          1.0|\n",
      "|       8|1395430|          2.0|\n",
      "|       8|1205593|          4.0|\n",
      "|       8|1488844|          4.0|\n",
      "|       8|1447354|          1.0|\n",
      "|       8| 306466|          4.0|\n",
      "|       8|1331154|          4.0|\n",
      "|       8|1818178|          3.0|\n",
      "|       8| 991725|          4.0|\n",
      "|       8|1987434|          4.0|\n",
      "|       8|1765381|          4.0|\n",
      "|       8| 433803|          3.0|\n",
      "|       8|1148143|          2.0|\n",
      "|       8|1174811|          5.0|\n",
      "|       8|1684516|          3.0|\n",
      "|       8| 754781|          4.0|\n",
      "|       8| 567025|          4.0|\n",
      "|       8|1623132|          4.0|\n",
      "|       8|1567095|          3.0|\n",
      "|       8|1666394|          5.0|\n",
      "+--------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|       8|1744889|          1.0|\n",
      "|       8|1395430|          2.0|\n",
      "|       8|1205593|          4.0|\n",
      "|       8|1488844|          4.0|\n",
      "|       8|1447354|          1.0|\n",
      "|       8| 306466|          4.0|\n",
      "|       8|1331154|          4.0|\n",
      "|       8|1818178|          3.0|\n",
      "|       8| 991725|          4.0|\n",
      "|       8|1987434|          4.0|\n",
      "+--------+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "movie_ids_with_avg_ratings_df:\n",
      "+--------+-----+------------------+\n",
      "|movie_Id|count|average           |\n",
      "+--------+-----+------------------+\n",
      "|4190    |9    |3.4444444444444446|\n",
      "|3220    |155  |2.7870967741935484|\n",
      "|3149    |25   |2.96              |\n",
      "+--------+-----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AverageUser_df = TrainingRatings_df.filter(\"movie_Id == 8\")\n",
    "AverageUser_df.show()\n",
    "\n",
    "list1 = AverageUser_df.select('user_Id')\n",
    "array = [int(row.user_Id) for row in list1.collect()]\n",
    "users = TrainingRatings_df[TrainingRatings_df['user_Id'].isin(array)]\n",
    "users.show(10)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "itemsusers = users.groupBy('movie_Id').agg(F.count(users.movie_ratings).alias(\"count\"),F.avg(users.movie_ratings).alias(\"average\"))\n",
    "print('movie_ids_with_avg_ratings_df:')\n",
    "itemsusers.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainingratings = TrainingRatings_df.toPandas()\n",
    "\n",
    "#pd_testing = df_testing.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_Id\n",
       "305344     1757\n",
       "387418     1744\n",
       "2439493    1640\n",
       "1664010    1535\n",
       "2118461    1481\n",
       "Name: movie_ratings, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rated movies per user:\n",
    "number_rated_movies = trainingratings.groupby(\"user_Id\")[\"movie_ratings\"].count().sort_values(ascending = False)\n",
    "number_rated_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_Id\n",
       "6971    25468\n",
       "6287    24393\n",
       "4640    23525\n",
       "9728    23184\n",
       "8596    23005\n",
       "Name: movie_ratings, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rated movies per user:\n",
    "rated_movies = trainingratings.groupby(\"movie_Id\")[\"movie_ratings\"].count().sort_values(ascending = False)\n",
    "rated_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_Id</th>\n",
       "      <th>8</th>\n",
       "      <th>28</th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>61</th>\n",
       "      <th>64</th>\n",
       "      <th>66</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>111</th>\n",
       "      <th>...</th>\n",
       "      <th>17654</th>\n",
       "      <th>17660</th>\n",
       "      <th>17689</th>\n",
       "      <th>17693</th>\n",
       "      <th>17706</th>\n",
       "      <th>17725</th>\n",
       "      <th>17728</th>\n",
       "      <th>17734</th>\n",
       "      <th>17741</th>\n",
       "      <th>17742</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_Id  8      28     43     48     61     64     66     92     96     \\\n",
       "user_Id                                                                   \n",
       "7           5.0    4.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "79          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "199         NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "481         NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "769         NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "movie_Id  111    ...  17654  17660  17689  17693  17706  17725  17728  17734  \\\n",
       "user_Id          ...                                                           \n",
       "7           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "79          NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "199         4.0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "481         5.0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "769         NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "movie_Id  17741  17742  \n",
       "user_Id                 \n",
       "7           NaN    NaN  \n",
       "79          NaN    NaN  \n",
       "199         NaN    NaN  \n",
       "481         NaN    NaN  \n",
       "769         NaN    NaN  \n",
       "\n",
       "[5 rows x 1821 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItemRating = train_rating.pivot_table(index='user_Id', columns='movie_Id', values='movie_ratings')\n",
    "userItemRating.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_Id</th>\n",
       "      <th>8</th>\n",
       "      <th>28</th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>61</th>\n",
       "      <th>64</th>\n",
       "      <th>66</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>111</th>\n",
       "      <th>...</th>\n",
       "      <th>17654</th>\n",
       "      <th>17660</th>\n",
       "      <th>17689</th>\n",
       "      <th>17693</th>\n",
       "      <th>17706</th>\n",
       "      <th>17725</th>\n",
       "      <th>17728</th>\n",
       "      <th>17734</th>\n",
       "      <th>17741</th>\n",
       "      <th>17742</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_Id  8      28     43     48     61     64     66     92     96     \\\n",
       "user_Id                                                                   \n",
       "7           5.0    4.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "79          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "199         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "481         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "769         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "movie_Id  111    ...  17654  17660  17689  17693  17706  17725  17728  17734  \\\n",
       "user_Id          ...                                                           \n",
       "7           0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "79          0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "199         4.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "481         5.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "769         0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "movie_Id  17741  17742  \n",
       "user_Id                 \n",
       "7           0.0    0.0  \n",
       "79          0.0    0.0  \n",
       "199         0.0    0.0  \n",
       "481         0.0    0.0  \n",
       "769         0.0    0.0  \n",
       "\n",
       "[5 rows x 1821 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItemRating.fillna(0, inplace = True)\n",
    "userItemRating.head()\n",
    "\n",
    "#userMovieRating = userItemRating.astype(np.int32)\n",
    "#userMovieRating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train= TrainingRatings_df.join(movie_titles_df,TrainingRatings_df.user_Id==movie_titles_df.ID)\n",
    "\n",
    "test = TestingRatings_df.join(movie_titles_df,TestingRatings_df.user_Id==movie_titles_df.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 2442110, validation: 813242\n",
      "\n",
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|       8|   1333|          3.0|\n",
      "|       8|   3321|          1.0|\n",
      "|       8|   3363|          2.0|\n",
      "+--------+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-------+-------------+\n",
      "|movie_Id|user_Id|movie_ratings|\n",
      "+--------+-------+-------------+\n",
      "|       8|      7|          5.0|\n",
      "|       8|   5980|          3.0|\n",
      "|       8|  13197|          3.0|\n",
      "+--------+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(split_60_df, split_a_20_df ) = TrainingRatings_df.randomSplit([7.5, 2.5])\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "train_df = split_60_df.cache()\n",
    "validation_df = split_a_20_df.cache()\n",
    "\n",
    "print('Training: {0}, validation: {1}\\n'.format(\n",
    "  train_df.count(), validation_df.count())\n",
    ")\n",
    "train_df.show(3)\n",
    "validation_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 1.0335312185835566\n",
      "Root-mean-square error = 1.068186779786811\n"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter=10, regParam=0.5, userCol=\"user_Id\", \n",
    "                      itemCol = \"movie_Id\", ratingCol = \"movie_ratings\", coldStartStrategy = \"drop\")\n",
    "\n",
    "model = als.fit(train_df)\n",
    "#Generating Predictions\n",
    "prediction = model.transform(validation_df)\n",
    "evaluate1 = RegressionEvaluator(metricName=\"mse\", labelCol=\"movie_ratings\",\n",
    "                                predictionCol=\"prediction\")\n",
    "                                            \n",
    "evaluate2 = RegressionEvaluator(metricName=\"rmse\", labelCol=\"movie_ratings\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "\n",
    "rmse = evaluate1.evaluate(prediction)\n",
    "mse = evaluate2.evaluate(prediction)\n",
    "\n",
    "print('The model had a MAE on the test set of {0}'.format(test_MAE))\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a MAE on the test set of 1.0718980704883263\n",
      "The model had a RMSE on the test set of 1.0353251037661195\n"
     ]
    }
   ],
   "source": [
    "##TestData\n",
    "predict_df = model.transform(TestingRatings_df)\n",
    "\n",
    "# Remove NaN values from prediction (due to SPARK-14489)\n",
    "predicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\n",
    "test_MAE = evaluate1.evaluate(predicted_test_df)\n",
    "test_RMSE = evaluate2.evaluate(predicted_test_df)\n",
    "\n",
    "print('The model had a MAE on the test set of {0}'.format(test_MAE))\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_Id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    481|[[3033, 4.8184724...|\n",
      "|   2678|[[3033, 3.8027837...|\n",
      "|   3595|[[3033, 3.4540896...|\n",
      "|   6460|[[3033, 3.9813197...|\n",
      "|   7284|[[3033, 4.2775936...|\n",
      "|   7576|[[3033, 4.167266]...|\n",
      "|   9597|[[3033, 3.7623503...|\n",
      "|  15191|[[3033, 4.0348988...|\n",
      "|  15846|[[3033, 4.372589]...|\n",
      "|  20461|[[3033, 3.8701422...|\n",
      "|  20774|[[3033, 3.494145]...|\n",
      "|  26258|[[3033, 4.073724]...|\n",
      "|  27608|[[3033, 4.1057005...|\n",
      "|  28346|[[3033, 3.7849407...|\n",
      "|  30941|[[3033, 3.8398561...|\n",
      "|  30976|[[3033, 4.201834]...|\n",
      "|  31203|[[3033, 3.7107627...|\n",
      "|  36822|[[3033, 4.242998]...|\n",
      "|  40851|[[3033, 3.864068]...|\n",
      "|  41068|[[3033, 3.2144418...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|movie_Id|     recommendations|\n",
      "+--------+--------------------+\n",
      "|    4190|[[1482568, 3.8478...|\n",
      "|    3220|[[1482568, 3.7492...|\n",
      "|   11240|[[1482568, 4.1383...|\n",
      "|    6110|[[1482568, 4.5736...|\n",
      "|    8260|[[1482568, 3.7770...|\n",
      "|   16232|[[1482568, 3.8100...|\n",
      "|    9492|[[1482568, 4.3529...|\n",
      "|     192|[[1482568, 3.8615...|\n",
      "|    9482|[[1482568, 4.7859...|\n",
      "|    6522|[[1482568, 5.1071...|\n",
      "|   10082|[[1482568, 3.3570...|\n",
      "|     122|[[1482568, 3.6513...|\n",
      "|   12184|[[1482568, 5.3169...|\n",
      "|    9324|[[1482568, 4.7813...|\n",
      "|    8354|[[1482568, 4.7814...|\n",
      "|   12755|[[1482568, 5.0170...|\n",
      "|   12705|[[1482568, 3.4352...|\n",
      "|    2675|[[1482568, 3.1082...|\n",
      "|    5465|[[1482568, 3.9623...|\n",
      "|   10845|[[1482568, 3.8776...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecommend = model.recommendForAllUsers(10)\n",
    "movieRecommend = model.recommendForAllItems(10)\n",
    "userRecommend.show()\n",
    "movieRecommend.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My movie ratings:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_Id: bigint, movie_Id: bigint, movie_ratings: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------------+\n",
      "|user_Id|movie_Id|movie_ratings|\n",
      "+-------+--------+-------------+\n",
      "|      1|   12293|            5|\n",
      "|      1|    2290|            5|\n",
      "|      1|   11812|            5|\n",
      "|      1|   25468|            5|\n",
      "|      1|   10947|            5|\n",
      "|      1|   14648|            3|\n",
      "|      1|   14185|            4|\n",
      "|      1|   11088|            3|\n",
      "|      1|    5326|            4|\n",
      "|      1|    3928|            2|\n",
      "+-------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "my_user_id = 1\n",
    "\n",
    "my_rated_movies = [\n",
    "    (my_user_id, 12293,  5),\n",
    "    (my_user_id, 10947,  5),\n",
    "    (my_user_id, 2290,  5),\n",
    "    (my_user_id, 14648,  3),\n",
    "    (my_user_id, 14185,  4),\n",
    "    (my_user_id, 11812,  5),\n",
    "    (my_user_id, 11088,  3),\n",
    "    (my_user_id, 25468,  5),\n",
    "    (my_user_id, 5326,  4),\n",
    "    (my_user_id, 3928,  2)\n",
    "     # The format of each line is (my_user_id, movie ID, your rating)\n",
    "     # For example, to give the movie \"Star Wars: Episode IV - A New Hope (1977)\" a five rating, you would add the following line:\n",
    "     #   (my_user_id, 260, 5),\n",
    "]\n",
    "\n",
    "my_ratings_df = sqlContext.createDataFrame(my_rated_movies, ['user_Id','movie_Id','movie_ratings'])\n",
    "print('My movie ratings:')\n",
    "display(my_ratings_df.limit(10))\n",
    "my_ratings_df.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
